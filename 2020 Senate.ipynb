{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-do\n",
    "* Impute NaN, by row, by column, by party vote?\n",
    "* Remove columns with >80% NaN\n",
    "* Save data in separate folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Congressional voting patterns go beyond Democrat vs. Republican party lines. In this project, I \"scrape\" voting record data from GovTrack, extract all the representatives and their votes, and perform clustering in order to determine subgroups within the Democratic and Republican parties. Interestingly, for both parties, there is a \"mainstream\" voting cluster and distant clusters that represent smaller factions within the parties. I performed this analysis for both the House of Representatives and the Senate, but I decided to focus my analysis on the Senate because there are fewer members, and those members are more widely known.\n",
    "### Goals\n",
    "My main goal was to build a data extraction pipeline for GovTrack that could be used to run interesting analyses on Congressional voting patterns from any year. \n",
    "### Data\n",
    "Data was \"scraped\" from https://www.govtrack.us/congress/votes. On this page are all the votes for both chambers of Congress that can be filtered by year, chamber, category, etc. In each vote's page, there is a .csv file that contains the names of all the present representatives and their vote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "Note: Many code cells are commented out because they take a long time to run.\n",
    "First, I \"scraped\" voting records from https://www.govtrack.us/congress/votes. \"Scraped\" is in quotations because BeautifulSoup could not detect the relevant information on the page for some reason. However, I noticed a pattern that each Congress (e.g. 116th Congress of 2020) is represented as \"votes/116-2020,\" the Senate is represented as \"s,\" and each vote is numbered numerically from the first to the last (e.g. s1-s239). This way, I could easily run a for loop to download the .csv of each vote from https://www.govtrack.us/congress/votes/116-2020/s[x]/export/csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "govtrack1 = pd.read_csv('govtrack1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download voting records (first batch)\n",
    "import urllib.request\n",
    "import os.path\n",
    "from os import mkdir\n",
    "for x in range(len(govtrack1)):\n",
    "    congress = govtrack1['Congress'][x]\n",
    "    year = govtrack1['Year'][x]\n",
    "    folder = 'C:/Users/HP/Dropbox/UMBC/Datasets/2020 Congress/Data-driven-Congressional-subgroups/data_senate/' + str(year)\n",
    "    mkdir(folder)\n",
    "    base = 'https://www.govtrack.us/congress/votes/' + str(congress) + '-' + str(year)\n",
    "    items = govtrack1['Items 1'][x]\n",
    "    for y in range(1, items + 1):\n",
    "        url = base + '/s' + str(y) + '/export/csv'\n",
    "        file = 'data_senate/' + str(year) + '/' + str(y) + '.csv'\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, file)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "govtrack2 = pd.read_csv('govtrack2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download voting records (second batch, different items structure)\n",
    "import urllib.request\n",
    "import os.path\n",
    "from os import mkdir\n",
    "for x in range(1, len(govtrack2)):\n",
    "    congress = govtrack2['Congress'][x]\n",
    "    year = govtrack2['Year'][x]\n",
    "    folder = 'C:/Users/HP/Dropbox/UMBC/Datasets/2020 Congress/Data-driven-Congressional-subgroups/data_senate/' + str(year)\n",
    "    mkdir(folder)\n",
    "    base = 'https://www.govtrack.us/congress/votes/' + str(congress) + '-' + str(year)\n",
    "    if (year % 2) == 0:\n",
    "        items_beg = govtrack2['Items 2'][x + 1] + 1\n",
    "        items_end = govtrack2['Items 2'][x]\n",
    "        for y in range(items_beg, items_end + 1):\n",
    "            url = base + '/s' + str(y) + '/export/csv'\n",
    "            file = 'data_senate/' + str(year) + '/' + str(y) + '.csv'\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, file)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        items_beg = 1\n",
    "        items_end = govtrack2['Items 2'][x]\n",
    "        for y in range(items_beg, items_end + 1):\n",
    "            url = base + '/s' + str(y) + '/export/csv'\n",
    "            file = 'data_senate/' + str(year) + '/' + str(y) + '.csv'\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, file)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bills\n",
    "import re\n",
    "import datetime\n",
    "def process_within_year(year, items_beg, items_end):\n",
    "    print(datetime.datetime.now())\n",
    "    print('Starting ' + str(year) + ' processing')\n",
    "    bills = []\n",
    "    passed = []\n",
    "    for x in range(items_beg, items_end + 1):\n",
    "        file = 'data_senate/' + str(year) + '/' + str(x) + '.csv'\n",
    "        try: \n",
    "            bills_data = pd.read_csv(file, nrows = 1)\n",
    "            bill = bills_data.columns[0]\n",
    "            bill = bill.split(' - ')[1]\n",
    "            # Remove commas\n",
    "            bill = bill.replace(',', '')\n",
    "            bills.append(bill)\n",
    "        except:\n",
    "            passed.append(x)\n",
    "        \n",
    "    # Extract votes\n",
    "    bill_nos = []\n",
    "    names = []\n",
    "    votes = []\n",
    "    party = []\n",
    "    for x in range(items_beg, items_end + 1):\n",
    "        file = 'data_senate/' + str(year) + '/' + str(x) + '.csv'\n",
    "        # Some files have extra bill rows or a blank row or are missing the header...\n",
    "        try: \n",
    "            if pd.read_csv(file, skiprows = 1).iloc[0].index[0] == 'person':\n",
    "                votes_data = pd.read_csv(file, skiprows = 1)\n",
    "            elif pd.read_csv(file, skiprows = 2).iloc[0].index[0] == 'person':\n",
    "                votes_data = pd.read_csv(file, skiprows = 2)\n",
    "            elif pd.read_csv(file, skiprows = 3).iloc[0].index[0] == 'person':\n",
    "                votes_data = pd.read_csv(file, skiprows = 3)\n",
    "            else: \n",
    "                votes_data = pd.read_csv('data_senate/1943/87.csv', skiprows = 0, header = None)\n",
    "                votes_data = test.iloc[:,0:6]\n",
    "                votes_data.columns = ['person', 'state', 'district', 'vote', 'name', 'party']\n",
    "            length = len(votes_data)\n",
    "            for y in range (0, length):\n",
    "                bill_nos.append(x)\n",
    "                names.append(votes_data.iloc[y]['name'])\n",
    "                votes.append(votes_data.iloc[y]['vote'])\n",
    "                party.append(votes_data.iloc[y]['party'])\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    # Get unique representatives\n",
    "    unique_names = set(names)\n",
    "    unique_names = list(unique_names)\n",
    "    \n",
    "    # Create data frame of all votes\n",
    "    all_votes = pd.DataFrame({'BillNo': bill_nos, 'Name': names, 'Vote': votes, 'Party': party})\n",
    "    \n",
    "    # Create final data frame for analysis\n",
    "    data = pd.DataFrame(columns = range(items_beg, items_end + 1))\n",
    "    data.insert(0, 'Representative', unique_names)\n",
    "    data.index = unique_names\n",
    "    data = data.drop('Representative', axis = 1)\n",
    "    data = data.drop(passed, axis = 1)\n",
    "    \n",
    "    # Fill in final data frame\n",
    "    for representative in unique_names:\n",
    "        for bill in range(items_beg, items_end + 1):\n",
    "            rep_record = all_votes[all_votes['Name'] == representative]\n",
    "            if bill in list(rep_record['BillNo']):\n",
    "                rep_voteonbill = rep_record[rep_record['BillNo'] == bill]['Vote'].iloc[0]\n",
    "                data.loc[representative][bill] = rep_voteonbill\n",
    "            else:\n",
    "                data.loc[representative][bill] = None\n",
    "     \n",
    "    # Name columns\n",
    "    data.columns = bills\n",
    "    \n",
    "    # Quantify data\n",
    "    data = data.replace('Nay', 0)\n",
    "    data = data.replace('No', 0)\n",
    "    data = data.replace('Yea', 1)\n",
    "    data = data.replace('Aye', 1)\n",
    "    data = data.replace('Not Voting', 0.5)\n",
    "    data = data.replace('Present', 0.5)\n",
    "    data = data.replace('Not Guilty', 0)\n",
    "    data = data.replace('Guilty', 1)\n",
    "    \n",
    "    # Remove rows with NaN\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Extract and insert party\n",
    "    party = []\n",
    "    for representative in data.index:\n",
    "        res = re.findall(r'\\[.*?\\]', representative)\n",
    "        res = res[0][1]\n",
    "        party.append(res)\n",
    "    data.insert(0, 'Party', party)\n",
    "\n",
    "    # Save to csv\n",
    "    print(datetime.datetime.now())\n",
    "    print('Saving ' + str(year) + ' data')\n",
    "    data.to_csv('data_senate/' + str(year) +'/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2003, 2020 + 1):\n",
    "    items_beg = 1\n",
    "    items_end = int(govtrack1['Items 1'][govtrack1['Year'] == year])\n",
    "    process_within_year(year, items_beg, items_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1972, 1988 + 1):\n",
    "    if (year % 2) == 0:\n",
    "        items_beg = int(govtrack2['Items 1'][govtrack2['Year'] == year - 1] + 1)\n",
    "        items_end = int(govtrack2['Items 2'][govtrack2['Year'] == year])\n",
    "        process_within_year(year, items_beg, items_end)\n",
    "    else:\n",
    "        items_beg = 1\n",
    "        items_end = int(govtrack2['Items 1'][govtrack2['Year'] == year])\n",
    "        process_within_year(year, items_beg, items_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "year = 1941\n",
    "file = 'data_senate/' + str(year) +'/data.csv'\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca.fit(data.iloc[:,2:].T)\n",
    "pca_data = pd.DataFrame(pca.components_)\n",
    "pca_data = pca_data.T\n",
    "pca_data.shape\n",
    "# Scatterplot of first two PCs with party as label\n",
    "sns.scatterplot(x = pca_data[0], y = pca_data[1], hue = data['Party'].values, palette = 'bright')\n",
    "print(pca.explained_variance_ratio_[0]*100, '% variance explained by PC1')\n",
    "print(pca.explained_variance_ratio_[1]*100, '% variance explained by PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by Democrats\n",
    "democrats = data[(data['Party'] == 'D') | (data['Party'] == 'I')]\n",
    "# Most divisive issues within Democratic Party\n",
    "democrats.std().sort_values(ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the contemporary American political system is so polarized, it is much more interesting to look at clusters within the two parties separately. Below, PCA is run on only Democratic (and Independent) senators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca.fit(democrats.iloc[:,1:].T)\n",
    "pca_data = pd.DataFrame(pca.components_)\n",
    "pca_data = pca_data.T\n",
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjectively, at first glance, there appears to be one large \"mainstream\" cluster and then two distant subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatterplot of first two PCs with party as label\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x = pca_data[0], y = pca_data[1], hue = democrats['Party'].values, palette = 'bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_[0]*100, '% variance explained by PC1')\n",
    "print(pca.explained_variance_ratio_[1]*100, '% variance explained by PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert PCs\n",
    "democrats.insert(0, 'PC1', pca_data[0].values)\n",
    "democrats.insert(0, 'PC2', pca_data[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale PCs before clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "democrats_small = democrats.iloc[:,:2]\n",
    "columns = democrats_small.columns\n",
    "index = democrats_small.index\n",
    "scaler = StandardScaler()\n",
    "democrats_small = scaler.fit_transform(democrats_small)\n",
    "democrats_small = pd.DataFrame(democrats_small)\n",
    "democrats_small.columns = columns\n",
    "democrats_small.index = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the elbow method to guide clustering (although in the end, I will personally choose a k value that makes the most sense to me)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters for K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from warnings import simplefilter\n",
    "simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "model = KMeans(random_state = 20201124)\n",
    "visualizer = KElbowVisualizer(model, k = (2,10), timings = False)\n",
    "visualizer.fit(democrats_small[['PC1', 'PC2']])\n",
    "elbow_visualizer = visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "k_means = KMeans(n_clusters = 4, random_state = 20201124)\n",
    "k_means.fit(democrats_small[['PC1', 'PC2']])\n",
    "cluster = k_means.predict(democrats_small[['PC1', 'PC2']])\n",
    "democrats_small.insert(0, 'Cluster', cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With k = 4, Democratic senators appear to be neatly divided into two groups of \"mainstream\" senators, and the two subgroups mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of first two PCs with cluster as label\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x = democrats_small['PC1'], y = democrats_small['PC2'], \n",
    "                hue = democrats_small['Cluster'].values, palette = 'bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first subgroup picks out the senators known to be the most progressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 0 = progressive Democrats\n",
    "democrats_small[democrats_small['Cluster'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second subgroup appears to pick out the [\"Red State Democrats\"](https://www.politico.com/news/2020/02/05/doug-jones-impeachment-vote-110818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 3 = Red State Democrats\n",
    "democrats_small[democrats_small['Cluster'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert cluster into main data frame\n",
    "democrats.insert(0, 'Cluster', cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's try the same thing for Republican senators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by Republicans\n",
    "republicans = data[data['Party'] == 'R']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most divisive issue within the Republican Party in 2020 was the Great American Outdoors Act, which aimed to provide funding for outdoors-related agencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most divisive issues within Republican Party\n",
    "republicans.std().sort_values(ascending = False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca.fit(republicans.iloc[:,1:].T)\n",
    "pca_data = pd.DataFrame(pca.components_)\n",
    "pca_data = pca_data.T\n",
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with Democratic senators, there appears to be a \"mainstream\" cluster and two distant subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of first two PCs\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x = pca_data[0], y = pca_data[1], palette = 'bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_[0]*100, '% variance explained by PC1')\n",
    "print(pca.explained_variance_ratio_[1]*100, '% variance explained by PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert PCs\n",
    "republicans.insert(0, 'PC1', pca_data[0].values)\n",
    "republicans.insert(0, 'PC2', pca_data[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale PCs before clustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "republicans_small = republicans.iloc[:,:2]\n",
    "columns = republicans_small.columns\n",
    "index = republicans_small.index\n",
    "scaler = StandardScaler()\n",
    "republicans_small = scaler.fit_transform(republicans_small)\n",
    "republicans_small = pd.DataFrame(republicans_small)\n",
    "republicans_small.columns = columns\n",
    "republicans_small.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters for K-Means\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from warnings import simplefilter\n",
    "simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "model = KMeans(random_state = 20201124)\n",
    "visualizer = KElbowVisualizer(model, k = (2,10), timings = False)\n",
    "visualizer.fit(republicans_small[['PC1', 'PC2']])\n",
    "elbow_visualizer = visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "k_means = KMeans(n_clusters = 4, random_state = 20201124)\n",
    "k_means.fit(republicans_small[['PC1', 'PC2']])\n",
    "cluster = k_means.predict(republicans_small[['PC1', 'PC2']])\n",
    "republicans_small.insert(0, 'Cluster', cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 4 nicely picks out the two subgroups and divides the mainstream cluster into two halves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of first two PCs with cluster as label\n",
    "import seaborn as sns\n",
    "sns.scatterplot(x = republicans_small['PC1'], y = republicans_small['PC2'], \n",
    "                hue = republicans_small['Cluster'].values, palette = 'bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first subgroup appears to pick out [the more liberal Republicans who took a firm stance against Trump](https://www.politico.com/news/2020/01/31/alexander-murkowski-collins-romney-impeachment-trial-110138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 2 =  liberal Republicans\n",
    "republicans_small[republicans_small['Cluster'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other subgroup appears to pick out the [radically conservative Tea Party members](https://www.politico.com/story/2011/01/4th-senator-joins-tea-party-caucus-048302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 3 = Tea Party Republicans\n",
    "republicans_small[republicans_small['Cluster'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert cluster into main data frame\n",
    "republicans.insert(0, 'Cluster', cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "One major limitation is that, as much as I tried, I could not find a meaningful interpretation of what PC1 and PC2 represent for both the Democratic and Republican parties. While it does appear to provide separation and aid in picking out the more fringe senators (e.g. progressives, Tea Partiers, etc.), it is very difficult to arrive at a sound conclusion as to what it actually represents. This is in comparison to PC1 for the Senate as a whole, which very obviously represents Democrats vs. Republicans.\n",
    "### Future directions\n",
    "In this project, I focus on the current year 2020, but in the future, it would be interesting to run analyses on multiple years and do a comparative analysis with regards to the degree of polarization, the most polarizing issues, the cluster structure, etc.\n",
    "### Conclusion\n",
    "I saw [this Tweet](https://twitter.com/seanjtaylor/status/1331426161356808192) today, and found it to encapsulate my motivation for pursuing this project: \"Perhaps my most controversial opinion: In machine learning education, the focus on supervised learning and particularly on classification problems gives people a totally misguided idea about how to use data to solve real problems.\" I wanted to avoid the mostly banal Kaggle/UCI datasets and build a pipeline to gather my own data. Congressional data does not lend itself to sophisticated machine learning classification/regression models, but I believe that by applying PCA + clustering to it, I learned a lot about the structure of our political system - data-driven knowledge that could not be attained just by reading the news. This pipeline could be used to gather data on any Congress, all the way back to the first Congress of 1789, and could provide the basis for very interesting quantitative comparisons of how American politics has evolved over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
